{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.collections import PatchCollection\n",
    "import seaborn as sns\n",
    "import statistics as stats\n",
    "from os import listdir\n",
    "# import cv2 \n",
    "# from skimage import img_as_float\n",
    "# from skimage import io, filters, color,exposure,feature,measure,segmentation\n",
    "# from scipy import ndimage\n",
    "import sys\n",
    "sys.path.append('../scripts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CNN_model import Resize_Alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resize_Alexnet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Resize_Alexnet(depth=4)\n",
    "model.to('cuda') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Resize_Alexnet(depth=1)\n",
    "model.to('cuda')\n",
    "model.eval()\n",
    "sipakmed_df_cnn1 = pd.DataFrame()\n",
    "folders = listdir('../data/Sipakmed database pictures/')[0:]\n",
    "\n",
    "for folder in folders:\n",
    "    for blob in glob.glob('../data/Sipakmed database pictures/{}/*.bmp'.format(folder)):\n",
    "        # read img\n",
    "        img = Image.open(blob)\n",
    "        # meets size requirements? \n",
    "        \n",
    "        # convert to tensor\n",
    "        img_as_tensor = transforms.ToTensor()(img).unsqueeze_(0)\n",
    "\n",
    "        # get features\n",
    "        features = model(img_as_tensor.to('cuda')).squeeze(axis=0).sum(axis=[1,2]).cpu().detach().numpy() #sum pooling, paper says good extractor\n",
    "\n",
    "        # make df, concatenate\n",
    "        df = pd.DataFrame(features).transpose()\n",
    "\n",
    "        df['cluster_id'] = int(blob.split('/')[-1][0:3])\n",
    "        df['Class'] = folder[3].lower()\n",
    "        if df['Class'].values in ['s','p']:\n",
    "            df['Normal']=1\n",
    "        else:\n",
    "            df['Normal']=0\n",
    "\n",
    "        sipakmed_df_cnn1 = pd.concat([sipakmed_df_cnn1,df])\n",
    "sipakmed_df_cnn1.to_csv('../data/sipakmed_cluster_cnn1')\n",
    "del model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Resize_Alexnet(depth=2)\n",
    "model.to('cuda')\n",
    "model.eval()\n",
    "sipakmed_df_cnn2 = pd.DataFrame()\n",
    "folders = listdir('../data/Sipakmed database pictures/')[0:]\n",
    "\n",
    "for folder in folders:\n",
    "    for blob in glob.glob('../data/Sipakmed database pictures/{}/*.bmp'.format(folder)):\n",
    "        # read img\n",
    "        img = Image.open(blob)\n",
    "        # meets size requirements? \n",
    "        \n",
    "        # convert to tensor\n",
    "        img_as_tensor = transforms.ToTensor()(img).unsqueeze_(0)\n",
    "\n",
    "        # get features\n",
    "        features = model(img_as_tensor.to('cuda')).squeeze(axis=0).sum(axis=[1,2]).cpu().detach().numpy() #sum pooling, paper says good extractor\n",
    "\n",
    "        # make df, concatenate\n",
    "        df = pd.DataFrame(features).transpose()\n",
    "\n",
    "        df['cluster_id'] = int(blob.split('/')[-1][0:3])\n",
    "        df['Class'] = folder[3].lower()\n",
    "        if df['Class'].values in ['s','p']:\n",
    "            df['Normal']=1\n",
    "        else:\n",
    "            df['Normal']=0\n",
    "\n",
    "        sipakmed_df_cnn2 = pd.concat([sipakmed_df_cnn2,df])\n",
    "sipakmed_df_cnn2.to_csv('../data/sipakmed_cluster_cnn2')\n",
    "del model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Resize_Alexnet(depth=3)\n",
    "model.to('cuda')\n",
    "model.eval()\n",
    "sipakmed_df_cnn3 = pd.DataFrame()\n",
    "folders = listdir('../data/Sipakmed database pictures/')[0:]\n",
    "\n",
    "for folder in folders:\n",
    "    for blob in glob.glob('../data/Sipakmed database pictures/{}/*.bmp'.format(folder)):\n",
    "        # read img\n",
    "        img = Image.open(blob)\n",
    "        # meets size requirements? \n",
    "        \n",
    "        # convert to tensor\n",
    "        img_as_tensor = transforms.ToTensor()(img).unsqueeze_(0)\n",
    "\n",
    "        # get features\n",
    "        features = model(img_as_tensor.to('cuda')).squeeze(axis=0).sum(axis=[1,2]).cpu().detach().numpy() #sum pooling, paper says good extractor\n",
    "\n",
    "        # make df, concatenate\n",
    "        df = pd.DataFrame(features).transpose()\n",
    "\n",
    "        df['cluster_id'] = int(blob.split('/')[-1][0:3])\n",
    "        df['Class'] = folder[3].lower()\n",
    "        if df['Class'].values in ['s','p']:\n",
    "            df['Normal']=1\n",
    "        else:\n",
    "            df['Normal']=0\n",
    "\n",
    "        sipakmed_df_cnn3 = pd.concat([sipakmed_df_cnn3,df])\n",
    "sipakmed_df_cnn3.to_csv('../data/sipakmed_cluster_cnn3')\n",
    "del model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Resize_Alexnet(depth=4)\n",
    "model.to('cuda')\n",
    "model.eval()\n",
    "sipakmed_df_cnn4 = pd.DataFrame()\n",
    "folders = listdir('../data/Sipakmed database pictures/')[0:]\n",
    "\n",
    "for folder in folders:\n",
    "    for blob in glob.glob('../data/Sipakmed database pictures/{}/*.bmp'.format(folder)):\n",
    "        # read img\n",
    "        img = Image.open(blob)\n",
    "        # meets size requirements? \n",
    "        \n",
    "        # convert to tensor\n",
    "        img_as_tensor = transforms.ToTensor()(img).unsqueeze_(0)\n",
    "\n",
    "        # get features\n",
    "        features = model(img_as_tensor.to('cuda')).squeeze(axis=0).sum(axis=[1,2]).cpu().detach().numpy() #sum pooling, paper says good extractor\n",
    "\n",
    "        # make df, concatenate\n",
    "        df = pd.DataFrame(features).transpose()\n",
    "\n",
    "        df['cluster_id'] = int(blob.split('/')[-1][0:3])\n",
    "        df['Class'] = folder[3].lower()\n",
    "        if df['Class'].values in ['s','p']:\n",
    "            df['Normal']=1\n",
    "        else:\n",
    "            df['Normal']=0\n",
    "\n",
    "        sipakmed_df_cnn4 = pd.concat([sipakmed_df_cnn4,df])\n",
    "sipakmed_df_cnn4.to_csv('../data/sipakmed_cluster_cnn4')\n",
    "del model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Resize_Alexnet(depth=4)\n",
    "model.to('cuda')\n",
    "model.eval()\n",
    "sipakmed_df_cnn5 = pd.DataFrame()\n",
    "folders = listdir('../data/Sipakmed database pictures/')[0:]\n",
    "\n",
    "for folder in folders:\n",
    "    for blob in glob.glob('../data/Sipakmed database pictures/{}/*.bmp'.format(folder)):\n",
    "        # read img\n",
    "        img = Image.open(blob)\n",
    "        # meets size requirements? \n",
    "        \n",
    "        # convert to tensor\n",
    "        img_as_tensor = transforms.ToTensor()(img).unsqueeze_(0)\n",
    "\n",
    "        # get features\n",
    "        features = model(img_as_tensor.to('cuda')).squeeze(axis=0).sum(axis=[1,2]).cpu().detach().numpy() #sum pooling, paper says good extractor\n",
    "\n",
    "        # make df, concatenate\n",
    "        df = pd.DataFrame(features).transpose()\n",
    "\n",
    "        df['cluster_id'] = int(blob.split('/')[-1][0:3])\n",
    "        df['Class'] = folder[3].lower()\n",
    "        if df['Class'].values in ['s','p']:\n",
    "            df['Normal']=1\n",
    "        else:\n",
    "            df['Normal']=0\n",
    "\n",
    "        sipakmed_df_cnn5 = pd.concat([sipakmed_df_cnn5,df])\n",
    "sipakmed_df_cnn5.to_csv('../data/sipakmed_cluster_cnn5')\n",
    "del model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import classification_report,accuracy_score, confusion_matrix, roc_curve, roc_auc_score, precision_score, recall_score, precision_recall_curve, auc, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92       231\n",
      "           1       0.83      0.85      0.84       117\n",
      "\n",
      "    accuracy                           0.89       348\n",
      "   macro avg       0.88      0.88      0.88       348\n",
      "weighted avg       0.89      0.89      0.89       348\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      "[[211  20]\n",
      " [ 18  99]]\n",
      "\n",
      "Area under the precision-recall curve: \n",
      "0.8649053785970622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erika/anaconda3/envs/pytorch_tf_gpu/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X = sipakmed_df_cnn1.drop(['cluster_id','Class','Normal'],axis=1)\n",
    "y = sipakmed_df_cnn1['Normal']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.5,random_state=42,stratify=y)\n",
    "\n",
    "clf1 = RandomForestClassifier(random_state=42)\n",
    "clf1.fit(X_train, y_train)\n",
    "\n",
    "# get some initial stats\n",
    "predictions = clf1.predict(X_test)\n",
    "print(f'Classification report: \\n{classification_report(y_test,predictions)}')\n",
    "print()\n",
    "print(f'Confusion matrix: \\n{confusion_matrix(y_test,predictions)}')\n",
    "print()\n",
    "# precision recall curve - better than the ROC for unbalanced data\n",
    "precision, recall, thresholds = precision_recall_curve(y_test,predictions)\n",
    "print(f'Area under the precision-recall curve: \\n{auc(recall,precision)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = '../models/Sipakmed_cluster_cnn1'\n",
    "pickle.dump(clf1,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95       231\n",
      "           1       0.94      0.83      0.88       117\n",
      "\n",
      "    accuracy                           0.93       348\n",
      "   macro avg       0.93      0.90      0.91       348\n",
      "weighted avg       0.93      0.93      0.92       348\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      "[[225   6]\n",
      " [ 20  97]]\n",
      "\n",
      "Area under the precision-recall curve: \n",
      "0.9141393331215896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erika/anaconda3/envs/pytorch_tf_gpu/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X = sipakmed_df_cnn2.drop(['cluster_id','Class','Normal'],axis=1)\n",
    "y = sipakmed_df_cnn2['Normal']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.5,random_state=42,stratify=y)\n",
    "\n",
    "clf2 = RandomForestClassifier(random_state=42)\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "# get some initial stats\n",
    "predictions = clf2.predict(X_test)\n",
    "print(f'Classification report: \\n{classification_report(y_test,predictions)}')\n",
    "print()\n",
    "print(f'Confusion matrix: \\n{confusion_matrix(y_test,predictions)}')\n",
    "print()\n",
    "# precision recall curve - better than the ROC for unbalanced data\n",
    "precision, recall, thresholds = precision_recall_curve(y_test,predictions)\n",
    "print(f'Area under the precision-recall curve: \\n{auc(recall,precision)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = '../models/Sipakmed_cluster_cnn2'\n",
    "pickle.dump(clf2,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94       231\n",
      "           1       0.97      0.79      0.87       117\n",
      "\n",
      "    accuracy                           0.92       348\n",
      "   macro avg       0.94      0.89      0.91       348\n",
      "weighted avg       0.93      0.92      0.92       348\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      "[[228   3]\n",
      " [ 24  93]]\n",
      "\n",
      "Area under the precision-recall curve: \n",
      "0.9162936560565871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erika/anaconda3/envs/pytorch_tf_gpu/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X = sipakmed_df_cnn3.drop(['cluster_id','Class','Normal'],axis=1)\n",
    "y = sipakmed_df_cnn3['Normal']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.5,random_state=42,stratify=y)\n",
    "\n",
    "clf3 = RandomForestClassifier(random_state=42)\n",
    "clf3.fit(X_train, y_train)\n",
    "\n",
    "# get some initial stats\n",
    "predictions = clf3.predict(X_test)\n",
    "print(f'Classification report: \\n{classification_report(y_test,predictions)}')\n",
    "print()\n",
    "print(f'Confusion matrix: \\n{confusion_matrix(y_test,predictions)}')\n",
    "print()\n",
    "# precision recall curve - better than the ROC for unbalanced data\n",
    "precision, recall, thresholds = precision_recall_curve(y_test,predictions)\n",
    "print(f'Area under the precision-recall curve: \\n{auc(recall,precision)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = '../models/Sipakmed_cluster_cnn3'\n",
    "pickle.dump(clf3,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93       231\n",
      "           1       0.97      0.73      0.83       117\n",
      "\n",
      "    accuracy                           0.90       348\n",
      "   macro avg       0.92      0.86      0.88       348\n",
      "weighted avg       0.91      0.90      0.90       348\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      "[[228   3]\n",
      " [ 32  85]]\n",
      "\n",
      "Area under the precision-recall curve: \n",
      "0.8921794201966615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erika/anaconda3/envs/pytorch_tf_gpu/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X = sipakmed_df_cnn4.drop(['cluster_id','Class','Normal'],axis=1)\n",
    "y = sipakmed_df_cnn4['Normal']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.5,random_state=42,stratify=y)\n",
    "\n",
    "clf4 = RandomForestClassifier(random_state=42)\n",
    "clf4.fit(X_train, y_train)\n",
    "\n",
    "# get some initial stats\n",
    "predictions = clf4.predict(X_test)\n",
    "print(f'Classification report: \\n{classification_report(y_test,predictions)}')\n",
    "print()\n",
    "print(f'Confusion matrix: \\n{confusion_matrix(y_test,predictions)}')\n",
    "print()\n",
    "# precision recall curve - better than the ROC for unbalanced data\n",
    "precision, recall, thresholds = precision_recall_curve(y_test,predictions)\n",
    "print(f'Area under the precision-recall curve: \\n{auc(recall,precision)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = '../models/Sipakmed_cluster_cnn4'\n",
    "pickle.dump(clf4,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93       231\n",
      "           1       0.97      0.73      0.83       117\n",
      "\n",
      "    accuracy                           0.90       348\n",
      "   macro avg       0.92      0.86      0.88       348\n",
      "weighted avg       0.91      0.90      0.90       348\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      "[[228   3]\n",
      " [ 32  85]]\n",
      "\n",
      "Area under the precision-recall curve: \n",
      "0.8921794201966615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erika/anaconda3/envs/pytorch_tf_gpu/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X = sipakmed_df_cnn5.drop(['cluster_id','Class','Normal'],axis=1)\n",
    "y = sipakmed_df_cnn5['Normal']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.5,random_state=42,stratify=y)\n",
    "\n",
    "clf5 = RandomForestClassifier(random_state=42)\n",
    "clf5.fit(X_train, y_train)\n",
    "\n",
    "# get some initial stats\n",
    "predictions = clf5.predict(X_test)\n",
    "print(f'Classification report: \\n{classification_report(y_test,predictions)}')\n",
    "print()\n",
    "print(f'Confusion matrix: \\n{confusion_matrix(y_test,predictions)}')\n",
    "print()\n",
    "# precision recall curve - better than the ROC for unbalanced data\n",
    "precision, recall, thresholds = precision_recall_curve(y_test,predictions)\n",
    "print(f'Area under the precision-recall curve: \\n{auc(recall,precision)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = '../models/Sipakmed_cluster_cnn5'\n",
    "pickle.dump(clf5,open(filename,'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
